{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Llama 3 on Mac, Windows or Linux\n",
    "This notebook goes over how you can set up and run Llama 3.1 locally on a Mac, Windows or Linux using [Ollama](https://ollama.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps at a glance:\n",
    "1. Download and install Ollama.\n",
    "2. Download and test run Llama 3.1\n",
    "3. Use local Llama 3.1 via Python.\n",
    "4. Use local Llama 3.1 via LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download and install Ollama\n",
    "\n",
    "On Mac or Windows, go to the Ollama download page [here](https://ollama.com/download) and select your platform to download it, then double click the downloaded file to install Ollama.\n",
    "\n",
    "On Linux, you can simply run on a terminal `curl -fsSL https://ollama.com/install.sh | sh` to download and install Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Download and test run Llama 3\n",
    "\n",
    "On a terminal or console, run `ollama pull llama3.1` to download the Llama 3.1 8b chat model, in the 4-bit quantized format with size about 4.7 GB.\n",
    "\n",
    "Run `ollama pull llama3.1:70b` to download the Llama 3.1 70b chat model, also in the 4-bit quantized format with size 39GB.\n",
    "\n",
    "Then you can run `ollama run llama3.1` and ask Llama 3.1 questions such as \"who wrote the book godfather?\" or \"who wrote the book godfather? answer in one sentence.\" You can also try `ollama run llama3.1:70b`, but the inference speed will most likely be too slow - for example, on an Apple M1 Pro with 32GB RAM, it takes over 10 seconds to generate one token using Llama 3.1 70b chat (vs over 10 tokens per second with Llama 3.1 8b chat).\n",
    "\n",
    "You can also run the following command to test Llama 3.1 8b chat:\n",
    "```\n",
    "curl http://localhost:11434/api/chat -d '{\n",
    "  \"model\": \"llama3.1\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"who wrote the book godfather?\"\n",
    "    }\n",
    "  ],\n",
    "  \"stream\": false\n",
    "}'\n",
    "```\n",
    "\n",
    "The complete Ollama API doc is [here](https://github.com/ollama/ollama/blob/main/docs/api.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use local Llama 3.1 via Python\n",
    "\n",
    "The Python code below is the port of the curl command above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "def llama3(prompt):\n",
    "    data = {\n",
    "        \"model\": \"llama3.1\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    return(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book \"The Godfather\" was written by Mario Puzo, an American author. The novel was published in 1969 and it's a fictional story about the Corleone crime family, but it's heavily influenced by real-life events and figures from the Italian-American Mafia.\n",
      "\n",
      "Mario Puzo is credited with creating the iconic characters of Don Vito Corleone (also known as \"The Godfather\") and his children, particularly Michael Corleone. The novel was a massive success, and it won the Pulitzer Prize for Fiction in 1973.\n",
      "\n",
      "Puzo's book was later adapted into the famous film directed by Francis Ford Coppola, which became one of the greatest films of all time. The movie starred Marlon Brando as Don Vito Corleone, Al Pacino as Michael Corleone, and James Caan as Sonny Corleone.\n",
      "\n",
      "Mario Puzo wrote two more books in the Godfather series: \"The Sicilian\" (1984) and \"The Fourth K\" (1992). However, his later works did not quite match the impact of his first novel.\n"
     ]
    }
   ],
   "source": [
    "response = llama3(\"who wrote the book godfather\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use local Llama 3.1 via LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain_community in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (3.11.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/wxgrp/luyanfeng/luyanfeng/fork-llama-recipes/env/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3940077/523496793.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3.1\", temperature=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The novel \"The Godfather\" was written by Mario Puzo. It was published in 1969 and became a huge success, leading to the famous film adaptation directed by Francis Ford Coppola in 1972.\n",
      "\n",
      "Mario Puzo (1920-1999) was an American author of Italian descent, born in New York City's Little Italy neighborhood. He wrote several novels, but \"The Godfather\" remains his most famous and enduring work. The book is a sprawling epic that explores the world of organized crime, family loyalty, and the American Dream.\n",
      "\n",
      "Interestingly, Puzo also co-wrote the screenplay for the film adaptation with Coppola, which won several Academy Awards, including Best Picture in 1973.\n",
      "\n",
      "Puzo went on to write two more novels set in the same universe: \"The Last Don\" (1996) and \"Omertà\" (2000), both of which were also adapted into films.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "response = llm.invoke(\"who wrote the book godfather?\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
